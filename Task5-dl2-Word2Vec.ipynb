{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用gensim训练word2vec\n",
    "\n",
    "本DEMO只使用部分数据，使用全部数据预训练的词向量地址：  \n",
    "\n",
    "链接: https://pan.baidu.com/s/1ewlck3zwXVQuAzraZ26Euw 提取码: qbpr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f65ad190930>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)-15s %(levelname)s: %(message)s')\n",
    "\n",
    "# set seed\n",
    "seed = 666\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 22:32:01,859 INFO: Fold lens [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 505\n",
      "51\n",
      "51\n",
      "51\n",
      "51\n",
      "51\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "50\n",
      "0 1885\n",
      "189\n",
      "189\n",
      "189\n",
      "189\n",
      "189\n",
      "188\n",
      "188\n",
      "188\n",
      "188\n",
      "188\n",
      "7 426\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "43\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "2 1561\n",
      "157\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "156\n",
      "11 164\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "1 1866\n",
      "187\n",
      "187\n",
      "187\n",
      "187\n",
      "187\n",
      "187\n",
      "186\n",
      "186\n",
      "186\n",
      "186\n",
      "3 1078\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "107\n",
      "107\n",
      "4 788\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "79\n",
      "78\n",
      "78\n",
      "9 310\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "31\n",
      "5 619\n",
      "62\n",
      "62\n",
      "62\n",
      "62\n",
      "62\n",
      "62\n",
      "62\n",
      "62\n",
      "62\n",
      "61\n",
      "8 415\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "41\n",
      "12 88\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "10 242\n",
      "25\n",
      "25\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "13 53\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# split data to 10 fold\n",
    "fold_num = 10\n",
    "data_file = 'data/train_set.csv'\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def all_data2fold(fold_num, num=10000):\n",
    "    fold_data = []\n",
    "    f = pd.read_csv(data_file, sep='\\t', encoding='UTF-8')\n",
    "    texts = f['text'].tolist()[:num]\n",
    "    labels = f['label'].tolist()[:num]\n",
    "\n",
    "    total = len(labels)\n",
    "\n",
    "    index = list(range(total))\n",
    "    np.random.shuffle(index)\n",
    "\n",
    "    all_texts = []\n",
    "    all_labels = []\n",
    "    for i in index:\n",
    "        all_texts.append(texts[i])\n",
    "        all_labels.append(labels[i])\n",
    "\n",
    "    label2id = {}\n",
    "    for i in range(total):\n",
    "        label = str(all_labels[i])\n",
    "        if label not in label2id:\n",
    "            label2id[label] = [i]\n",
    "        else:\n",
    "            label2id[label].append(i)\n",
    "\n",
    "    all_index = [[] for _ in range(fold_num)]\n",
    "    for label, data in label2id.items():\n",
    "        print(label, len(data))\n",
    "        batch_size = int(len(data) / fold_num)\n",
    "        other = len(data) - batch_size * fold_num\n",
    "        for i in range(fold_num):\n",
    "            cur_batch_size = batch_size + 1 if i < other else batch_size\n",
    "            print(cur_batch_size)\n",
    "            batch_data = [data[i * batch_size + b] for b in range(cur_batch_size)]\n",
    "            all_index[i].extend(batch_data)\n",
    "\n",
    "    batch_size = int(total / fold_num)\n",
    "    other_texts = []\n",
    "    other_labels = []\n",
    "    other_num = 0\n",
    "    start = 0\n",
    "    for fold in range(fold_num):\n",
    "        num = len(all_index[fold])\n",
    "        texts = [all_texts[i] for i in all_index[fold]]\n",
    "        labels = [all_labels[i] for i in all_index[fold]]\n",
    "\n",
    "        if num > batch_size:\n",
    "            fold_texts = texts[:batch_size]\n",
    "            other_texts.extend(texts[batch_size:])\n",
    "            fold_labels = labels[:batch_size]\n",
    "            other_labels.extend(labels[batch_size:])\n",
    "            other_num += num - batch_size\n",
    "        elif num < batch_size:\n",
    "            end = start + batch_size - num\n",
    "            fold_texts = texts + other_texts[start: end]\n",
    "            fold_labels = labels + other_labels[start: end]\n",
    "            start = end\n",
    "        else:\n",
    "            fold_texts = texts\n",
    "            fold_labels = labels\n",
    "\n",
    "        assert batch_size == len(fold_labels)\n",
    "\n",
    "        # shuffle\n",
    "        index = list(range(batch_size))\n",
    "        np.random.shuffle(index)\n",
    "\n",
    "        shuffle_fold_texts = []\n",
    "        shuffle_fold_labels = []\n",
    "        for i in index:\n",
    "            shuffle_fold_texts.append(fold_texts[i])\n",
    "            shuffle_fold_labels.append(fold_labels[i])\n",
    "\n",
    "        data = {'label': shuffle_fold_labels, 'text': shuffle_fold_texts}\n",
    "        fold_data.append(data)\n",
    "\n",
    "    logging.info(\"Fold lens %s\", str([len(data['label']) for data in fold_data]))\n",
    "\n",
    "    return fold_data\n",
    "\n",
    "\n",
    "fold_data = all_data2fold(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 22:32:03,398 INFO: Total 9000 docs.\n"
     ]
    }
   ],
   "source": [
    "# build train data for word2vec\n",
    "fold_id = 9\n",
    "\n",
    "train_texts = []\n",
    "for i in range(0, fold_id):\n",
    "    data = fold_data[i]\n",
    "    train_texts.extend(data['text'])\n",
    "    \n",
    "logging.info('Total %d docs.' % len(train_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /root/anaconda3/envs/py37_torch131/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /root/anaconda3/envs/py37_torch131/lib/python3.7/site-packages (from gensim) (1.5.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /root/anaconda3/envs/py37_torch131/lib/python3.7/site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /root/anaconda3/envs/py37_torch131/lib/python3.7/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /root/anaconda3/envs/py37_torch131/lib/python3.7/site-packages (from gensim) (2.1.0)\n",
      "Requirement already satisfied: boto in /root/anaconda3/envs/py37_torch131/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /root/anaconda3/envs/py37_torch131/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.14.28)\n",
      "Requirement already satisfied: requests in /root/anaconda3/envs/py37_torch131/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.24.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /root/anaconda3/envs/py37_torch131/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.28 in /root/anaconda3/envs/py37_torch131/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.28)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /root/anaconda3/envs/py37_torch131/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /root/anaconda3/envs/py37_torch131/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /root/anaconda3/envs/py37_torch131/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /root/anaconda3/envs/py37_torch131/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/envs/py37_torch131/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.4.5.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /root/anaconda3/envs/py37_torch131/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.28->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /root/anaconda3/envs/py37_torch131/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.28->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 22:33:05,846 INFO: Start training...\n",
      "2020-07-31 22:33:09,397 INFO: collecting all words and their counts\n",
      "2020-07-31 22:33:09,433 INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-07-31 22:33:12,283 INFO: collected 5295 word types from a corpus of 8191447 raw words and 9000 sentences\n",
      "2020-07-31 22:33:12,303 INFO: Loading a fresh vocabulary\n",
      "2020-07-31 22:33:13,495 INFO: effective_min_count=5 retains 4335 unique words (81% of original 5295, drops 960)\n",
      "2020-07-31 22:33:13,496 INFO: effective_min_count=5 leaves 8189498 word corpus (99% of original 8191447, drops 1949)\n",
      "2020-07-31 22:33:13,532 INFO: deleting the raw counts dictionary of 5295 items\n",
      "2020-07-31 22:33:13,534 INFO: sample=0.001 downsamples 61 most-common words\n",
      "2020-07-31 22:33:13,535 INFO: downsampling leaves estimated 7070438 word corpus (86.3% of prior 8189498)\n",
      "2020-07-31 22:33:13,552 INFO: estimated required memory for 4335 words and 100 dimensions: 5635500 bytes\n",
      "2020-07-31 22:33:13,554 INFO: resetting layer weights\n",
      "2020-07-31 22:33:15,651 INFO: training model with 8 workers on 4335 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-07-31 22:33:16,683 INFO: EPOCH 1 - PROGRESS: at 13.06% examples, 905417 words/s, in_qsize 14, out_qsize 1\n",
      "2020-07-31 22:33:17,696 INFO: EPOCH 1 - PROGRESS: at 24.94% examples, 865442 words/s, in_qsize 12, out_qsize 3\n",
      "2020-07-31 22:33:18,706 INFO: EPOCH 1 - PROGRESS: at 37.42% examples, 868394 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-31 22:33:19,710 INFO: EPOCH 1 - PROGRESS: at 50.04% examples, 863497 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-31 22:33:20,710 INFO: EPOCH 1 - PROGRESS: at 60.69% examples, 845720 words/s, in_qsize 15, out_qsize 1\n",
      "2020-07-31 22:33:21,740 INFO: EPOCH 1 - PROGRESS: at 71.62% examples, 833500 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-31 22:33:22,763 INFO: EPOCH 1 - PROGRESS: at 82.57% examples, 817899 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-31 22:33:23,779 INFO: EPOCH 1 - PROGRESS: at 93.40% examples, 810051 words/s, in_qsize 13, out_qsize 2\n",
      "2020-07-31 22:33:24,245 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2020-07-31 22:33:24,252 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2020-07-31 22:33:24,257 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2020-07-31 22:33:24,259 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2020-07-31 22:33:24,264 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-31 22:33:24,267 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-31 22:33:24,275 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-31 22:33:24,300 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-31 22:33:24,302 INFO: EPOCH - 1 : training on 8191447 raw words (7021003 effective words) took 8.6s, 813218 effective words/s\n",
      "2020-07-31 22:33:25,341 INFO: EPOCH 2 - PROGRESS: at 13.49% examples, 940545 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-31 22:33:26,353 INFO: EPOCH 2 - PROGRESS: at 25.74% examples, 895908 words/s, in_qsize 16, out_qsize 5\n",
      "2020-07-31 22:33:27,352 INFO: EPOCH 2 - PROGRESS: at 38.21% examples, 891491 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-31 22:33:28,380 INFO: EPOCH 2 - PROGRESS: at 50.61% examples, 871283 words/s, in_qsize 11, out_qsize 5\n",
      "2020-07-31 22:33:29,382 INFO: EPOCH 2 - PROGRESS: at 62.04% examples, 864033 words/s, in_qsize 16, out_qsize 1\n",
      "2020-07-31 22:33:30,402 INFO: EPOCH 2 - PROGRESS: at 72.12% examples, 839038 words/s, in_qsize 15, out_qsize 1\n",
      "2020-07-31 22:33:31,432 INFO: EPOCH 2 - PROGRESS: at 83.12% examples, 821305 words/s, in_qsize 14, out_qsize 1\n",
      "2020-07-31 22:33:32,433 INFO: EPOCH 2 - PROGRESS: at 96.28% examples, 836852 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-31 22:33:32,640 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2020-07-31 22:33:32,644 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2020-07-31 22:33:32,647 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2020-07-31 22:33:32,657 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2020-07-31 22:33:32,659 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-31 22:33:32,670 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-31 22:33:32,676 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-31 22:33:32,692 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-31 22:33:32,695 INFO: EPOCH - 2 : training on 8191447 raw words (7022261 effective words) took 8.4s, 839487 effective words/s\n",
      "2020-07-31 22:33:33,726 INFO: EPOCH 3 - PROGRESS: at 12.36% examples, 860330 words/s, in_qsize 13, out_qsize 2\n",
      "2020-07-31 22:33:34,744 INFO: EPOCH 3 - PROGRESS: at 25.93% examples, 900079 words/s, in_qsize 15, out_qsize 1\n",
      "2020-07-31 22:33:35,769 INFO: EPOCH 3 - PROGRESS: at 40.11% examples, 923999 words/s, in_qsize 16, out_qsize 3\n",
      "2020-07-31 22:33:36,776 INFO: EPOCH 3 - PROGRESS: at 51.80% examples, 888149 words/s, in_qsize 16, out_qsize 1\n",
      "2020-07-31 22:33:37,800 INFO: EPOCH 3 - PROGRESS: at 61.79% examples, 854775 words/s, in_qsize 14, out_qsize 1\n",
      "2020-07-31 22:33:38,800 INFO: EPOCH 3 - PROGRESS: at 73.39% examples, 850175 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-31 22:33:39,808 INFO: EPOCH 3 - PROGRESS: at 85.60% examples, 848723 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-31 22:33:40,842 INFO: EPOCH 3 - PROGRESS: at 97.70% examples, 845320 words/s, in_qsize 16, out_qsize 1\n",
      "2020-07-31 22:33:40,956 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2020-07-31 22:33:40,959 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2020-07-31 22:33:40,960 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2020-07-31 22:33:40,962 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2020-07-31 22:33:40,965 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-31 22:33:40,988 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-31 22:33:41,005 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-31 22:33:41,007 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-31 22:33:41,008 INFO: EPOCH - 3 : training on 8191447 raw words (7021671 effective words) took 8.3s, 846476 effective words/s\n",
      "2020-07-31 22:33:42,062 INFO: EPOCH 4 - PROGRESS: at 9.23% examples, 637851 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-31 22:33:43,095 INFO: EPOCH 4 - PROGRESS: at 21.63% examples, 734316 words/s, in_qsize 12, out_qsize 3\n",
      "2020-07-31 22:33:44,106 INFO: EPOCH 4 - PROGRESS: at 34.49% examples, 791138 words/s, in_qsize 14, out_qsize 1\n",
      "2020-07-31 22:33:45,120 INFO: EPOCH 4 - PROGRESS: at 46.32% examples, 797574 words/s, in_qsize 14, out_qsize 1\n",
      "2020-07-31 22:33:46,130 INFO: EPOCH 4 - PROGRESS: at 57.51% examples, 789100 words/s, in_qsize 14, out_qsize 1\n",
      "2020-07-31 22:33:47,147 INFO: EPOCH 4 - PROGRESS: at 69.07% examples, 797953 words/s, in_qsize 14, out_qsize 1\n",
      "2020-07-31 22:33:48,159 INFO: EPOCH 4 - PROGRESS: at 81.56% examples, 805064 words/s, in_qsize 16, out_qsize 0\n",
      "2020-07-31 22:33:49,169 INFO: EPOCH 4 - PROGRESS: at 93.78% examples, 812223 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-31 22:33:49,563 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2020-07-31 22:33:49,567 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2020-07-31 22:33:49,570 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2020-07-31 22:33:49,576 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2020-07-31 22:33:49,577 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-31 22:33:49,581 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-31 22:33:49,594 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-31 22:33:49,597 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-31 22:33:49,598 INFO: EPOCH - 4 : training on 8191447 raw words (7021788 effective words) took 8.6s, 820573 effective words/s\n",
      "2020-07-31 22:33:50,609 INFO: EPOCH 5 - PROGRESS: at 14.19% examples, 990718 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-31 22:33:51,623 INFO: EPOCH 5 - PROGRESS: at 27.88% examples, 974287 words/s, in_qsize 14, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 22:33:52,637 INFO: EPOCH 5 - PROGRESS: at 39.56% examples, 921384 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-31 22:33:53,650 INFO: EPOCH 5 - PROGRESS: at 52.92% examples, 914639 words/s, in_qsize 14, out_qsize 1\n",
      "2020-07-31 22:33:54,660 INFO: EPOCH 5 - PROGRESS: at 63.73% examples, 886503 words/s, in_qsize 13, out_qsize 2\n",
      "2020-07-31 22:33:55,670 INFO: EPOCH 5 - PROGRESS: at 74.80% examples, 870323 words/s, in_qsize 12, out_qsize 3\n",
      "2020-07-31 22:33:56,674 INFO: EPOCH 5 - PROGRESS: at 86.39% examples, 860421 words/s, in_qsize 16, out_qsize 2\n",
      "2020-07-31 22:33:57,680 INFO: EPOCH 5 - PROGRESS: at 96.08% examples, 838282 words/s, in_qsize 16, out_qsize 0\n",
      "2020-07-31 22:33:57,954 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2020-07-31 22:33:57,959 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2020-07-31 22:33:57,961 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2020-07-31 22:33:57,974 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2020-07-31 22:33:57,978 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-31 22:33:57,982 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-31 22:33:57,986 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-31 22:33:57,988 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-31 22:33:57,990 INFO: EPOCH - 5 : training on 8191447 raw words (7022676 effective words) took 8.4s, 837846 effective words/s\n",
      "2020-07-31 22:33:57,992 INFO: training on a 40957235 raw words (35109399 effective words) took 42.3s, 829296 effective words/s\n",
      "2020-07-31 22:33:58,005 INFO: precomputing L2-norms of word weight vectors\n",
      "2020-07-31 22:33:58,014 INFO: saving Word2Vec object under word2vec_7.bin, separately None\n",
      "2020-07-31 22:33:58,017 INFO: not storing attribute vectors_norm\n",
      "2020-07-31 22:33:58,019 INFO: not storing attribute cum_table\n",
      "2020-07-31 22:33:58,147 INFO: saved word2vec_7.bin\n"
     ]
    }
   ],
   "source": [
    "logging.info('Start training...')\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "num_features = 100     # Word vector dimensionality\n",
    "num_workers = 8       # Number of threads to run in parallel\n",
    "\n",
    "train_texts = list(map(lambda x: list(x.split()), train_texts))\n",
    "model = Word2Vec(train_texts, workers=num_workers, size=num_features)\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# save model\n",
    "model.save(\"word2vec_7.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-31 22:33:58,163 INFO: loading Word2Vec object from word2vec_726.bin\n",
      "2020-07-31 22:33:58,219 INFO: loading wv recursively from word2vec_726.bin.wv.* with mmap=None\n",
      "2020-07-31 22:33:58,221 INFO: setting ignored attribute vectors_norm to None\n",
      "2020-07-31 22:33:58,223 INFO: loading vocabulary recursively from word2vec_726.bin.vocabulary.* with mmap=None\n",
      "2020-07-31 22:33:58,224 INFO: loading trainables recursively from word2vec_726.bin.trainables.* with mmap=None\n",
      "2020-07-31 22:33:58,225 INFO: setting ignored attribute cum_table to None\n",
      "2020-07-31 22:33:58,227 INFO: loaded word2vec_726.bin\n",
      "2020-07-31 22:33:58,245 INFO: storing 4327x100 projection weights into word2vec.txt\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = Word2Vec.load(\"word2vec_726.bin\")\n",
    "\n",
    "# convert format\n",
    "model.wv.save_word2vec_format('word2vec.txt', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**关于Datawhale：**\n",
    "\n",
    "> Datawhale是一个专注于数据科学与AI领域的开源组织，汇集了众多领域院校和知名企业的优秀学习者，聚合了一群有开源精神和探索精神的团队成员。Datawhale 以“for the learner，和学习者一起成长”为愿景，鼓励真实地展现自我、开放包容、互信互助、敢于试错和勇于担当。同时 Datawhale 用开源的理念去探索开源内容、开源学习和开源方案，赋能人才培养，助力人才成长，建立起人与人，人与知识，人与企业和人与未来的联结。\n",
    "\n",
    "本次新闻文本分类学习，专题知识将在天池分享，详情可关注Datawhale：\n",
    "\n",
    " ![](http://jupter-oss.oss-cn-hangzhou.aliyuncs.com/public/files/image/1095279172547/1584432602983_kAxAvgQpG2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
